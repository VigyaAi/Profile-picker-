{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00d26a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Import libraries (Run this cell to execute required code) {display-mode: \"form\"}\n",
    "import sys\n",
    "import json\n",
    "import cohere\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "import umap\n",
    "import altair as alt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from annoy import AnnoyIndex\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# job_disc = \"Neep a person good in ML and Python, It will be good to have web development skills\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "700e7e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_resume(job_disc):\n",
    "\n",
    "    # Paste your API key here. Remember to not share publicly\n",
    "    api_key = '5EHSqcowINTyCK2uCkun3jj68NH6X63Z0z711JHb'\n",
    "\n",
    "    # Create and retrieve a Cohere API key from os.cohere.ai\n",
    "    co = cohere.Client(api_key)\n",
    "\n",
    "    # Get dataset\n",
    "    df = pd.read_csv(r\"data\\resume_data.csv\")\n",
    "    # Preview the data to ensure it has loaded correctly\n",
    "    df.head()\n",
    "\n",
    "    # Get the embeddings\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    new_df = pd.DataFrame({\"pdf_path\": [\"\"], \"id\":[0], \"text\":job_disc})\n",
    "\n",
    "    df = pd.concat([new_df, df])\n",
    "\n",
    "\n",
    "\n",
    "    embeds = co.embed(texts=list(df['text']),\n",
    "                  model=\"large\",\n",
    "                  truncate=\"LEFT\").embeddings\n",
    "\n",
    "\n",
    "    # Check the dimensions of the embeddings\n",
    "    embeds = np.array(embeds)\n",
    "    embeds.shape\n",
    "\n",
    "    # Create the search index, pass the size of embedding\n",
    "    search_index = AnnoyIndex(embeds.shape[1], 'angular')\n",
    "    # Add all the vectors to the search index\n",
    "    for i in range(len(embeds)):\n",
    "        search_index.add_item(i, embeds[i])\n",
    "\n",
    "    search_index.build(10) # 10 trees\n",
    "#     search_index.save('test.ann')\n",
    "\n",
    "    # Choose an example (we'll retrieve others similar to it)\n",
    "    example_id = 0\n",
    "    \n",
    "    # Retrieve nearest neighbors\n",
    "    similar_item_ids = search_index.get_nns_by_item(example_id,10,\n",
    "                                                    include_distances=True)\n",
    "    # Format and print the text and distances\n",
    "    results = pd.DataFrame(data={'texts': df.iloc[similar_item_ids[0]]['text'], \n",
    "                             'distance': similar_item_ids[1]}).drop(example_id)\n",
    "\n",
    "    print(f\"Question:'{df.iloc[example_id]['text']}'\\nNearest neighbors:\")\n",
    "    results\n",
    "\n",
    "\n",
    "    sel_pdf_paths = list(df.iloc[results.index+1, :].pdf_path)\n",
    "    score_list = list(results.distance)\n",
    "\n",
    "    # names_list = [i.split(\" \")[0] for i in df.iloc[results.index+1, :].text]\n",
    "    # names_list\n",
    "\n",
    "\n",
    "    res_dict = {i:j for i, j in zip(sel_pdf_paths, score_list)}\n",
    "\n",
    "\n",
    "    out_file = open(\"gen_data.json\", \"w\")\n",
    "    json.dump(res_dict, out_file)\n",
    "\n",
    "    print(res_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0ca6387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:'c:\\users\\acer\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\ipykernel_launcher.py'\n",
      "Nearest neighbors:\n",
      "{'data\\\\pdf_data\\\\34.pdf': 1.2199931144714355, 'data\\\\pdf_data\\\\85.pdf': 1.2456215620040894, 'data\\\\pdf_data\\\\86.pdf': 1.2456215620040894, 'data\\\\pdf_data\\\\81.pdf': 1.2488250732421875, 'data\\\\pdf_data\\\\26.pdf': 1.2557923793792725, 'data\\\\pdf_data\\\\38.pdf': 1.2594094276428223, 'data\\\\pdf_data\\\\17.pdf': 1.2640026807785034, 'data\\\\pdf_data\\\\57.pdf': 1.2651052474975586}\n",
      "gen_data.json\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    dataToSendBack = sort_resume(sys.argv[0])\n",
    "    \n",
    "    print(\"gen_data.json\")\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64049605",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
